torch>=2.1.0
transformers>=4.35.0
datasets>=2.14.0
tokenizers>=0.15.0
numpy>=1.24.0
tqdm>=4.65.0
wandb>=0.16.0
tensorboard>=2.15.0
safetensors>=0.4.0
pyyaml>=6.0
sentencepiece>=0.1.99
einops>=0.7.0

# Optional optimizations (comment out if installation issues)
# flash-attn>=2.3.0  # Requires CUDA compilation
# bitsandbytes>=0.41.0  # For 8-bit optimizer
